{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Jeu de données IRVE*\n",
    "-------------------\n",
    "# Analyse des relations entre champs (intégrité des données)\n",
    "------------------------------\n",
    "## Contexte\n",
    "- clarification du rôle des modèles de données dans les jeux de données (cf mise à jour récente des [guides data.gouv](https://guides.etalab.gouv.fr/qualite/documenter-les-donnees/))\n",
    "- intégration d'une propriété \"relationship\" dans les schémas de données ([issue TableSchema](https://github.com/frictionlessdata/specs/issues/803) en cours de validation)\n",
    "- création d'outils de contrôle des relations entre champs des jeux de données tabulaires (cf usage ci-dessous)\n",
    "\n",
    "## Objectifs\n",
    "- valider sur un cas réel l'utilisation d'un modèle de données en complément d'un schéma de données\n",
    "- identifier les apports que pourraient avoir les contrôles de validation des relations entre champs\n",
    "\n",
    "## Résultats\n",
    "- la formalisation d'un modèle de données facilite la compréhension des données et des relations entre champs\n",
    "- l'outil de contrôle permet d'améliorer significativement la qualité des données par l'identification d'incohérences de relations\n",
    "- l'identification des incohérences permet de trouver des stratégies de réduction des écarts (dans l'exemple ci-dessous, on passe 36% d'écart à 3,8 %)  \n",
    "- l'analyse des données permet de (re)construire le modèle de données qui minimise les incohérences\n",
    "- les incohérences détectées sur le jeu de données IRVE restent faibles (inférieures à 4% des point de charge documentés - voir chapitre 4)\n",
    "\n",
    "## Suite à donner\n",
    "- Mettre à jour, valider et publier le modèle de données IRVE\n",
    "- Définir les contrôles supplémentaires à intégrer pour toutes nouvelles données ainsi que pour le jeu complet\n",
    "- Mettre en oeuvre les outils de contrôle\n",
    "\n",
    "## Evolutions possibles \n",
    "- Ajouter dans les guides d'Etalab un guide pour les modèles de données \n",
    "- Intégrer dans les schémas de données la propriété \"relationship\" en cours de validation,\n",
    "- Définir un indicateur qui mesure l'écart (existant / attendu) des relations entre champs\n",
    "\n",
    "## Sommaire\n",
    "*(liens actifs sur jupyter Notebook ou Nbviewer)*\n",
    "- [1 - modèle de données](#1---modèle-de-données)\n",
    "- [2 - Initialisation](#2---Initialisation)\n",
    "- [3 - Séparation des pdc itinerance et hors itinerance](#3---Séparation-des-pdc-itinerance-et-hors-itinerance)\n",
    "- [4 - Bilan initial intégrité](#4---Bilan-initial-intégrité)\n",
    "- [5 - Séparation doublons pdc - date de maj](#5---Séparation-doublons-pdc---date-de-maj)\n",
    "- [6 - Séparation doublons station - date de maj](#6---Séparation-doublons-station---date-de-maj)\n",
    "- [7 - Synthèse](#7---Synthèse)\n",
    "- [8 - Exemples d'erreurs résiduelles](#8---Exemples-d\\'erreurs-résiduelles)\n",
    "\n",
    "Ce Notebook peut être consulté sur [nbviewer](http://nbviewer.org/github/loco-philippe/Environmental-Sensing/tree/main/python/Validation/irve/Analyse)\n",
    "\n",
    "données utilisées : https://www.data.gouv.fr/fr/datasets/fichier-consolide-des-bornes-de-recharge-pour-vehicules-electriques/    \n",
    "fichier : \"*consolidation-etalab-schema-irve-statique-v-2.2.0-20230303.csv*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# 1 - modèle de données\n",
    "\n",
    "Le modèle de données proposé ci-dessous est construit sur la base du schéma de données mis à disposition et du contenu du jeu de données.    \n",
    "Il est à consolider en fonction de l'expertise des concepteurs et réutilisateurs (voir [guide méthodologique](https://github.com/loco-philippe/Environmental-Sensing/blob/main/property_relationship/FR_methodology.ipynb)).\n",
    "\n",
    "*Notation:*\n",
    "- *M : Mandatory - documentation obligatoire*\n",
    "- *PK : Primary Key - identifiant unique de l'entité*\n",
    "- *Root : champ fictif associé à une ligne du tableau*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.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\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from base64 import b64encode\n",
    "from IPython.display import Image, display\n",
    "with open('IRVE_modele.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    modele = f.read()\n",
    "display(Image(url=\"https://mermaid.ink/img/\" + b64encode(modele.encode(\"ascii\")).decode(\"ascii\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_integrite(data, fields, pr=True):\n",
    "    '''analyse les relations du DataFrame définies dans le dict fields et retourne un dict avec pour chaque contrôle la\n",
    "    liste des index ko. Les résultats des contrôles sont également ajoutés sous forme de champs booléens à data'''\n",
    "    analyse = Analysis(data)\n",
    "    dic_res = analyse.check_relationship(fields)\n",
    "    data['ok'] = True\n",
    "    for name, lis in dic_res.items():\n",
    "        data[name] = True\n",
    "        data.loc[lis, name] = False\n",
    "        data['ok'] = data['ok'] & data[name]\n",
    "        if pr:\n",
    "            print('{:<50} {:>5}'.format(name, len(data) - data[name].sum()))\n",
    "    return dic_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# 2 - Initialisation\n",
    "## initialisation des données\n",
    "- lecture du fichier issu de l'api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18136\\776850641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#log = {'date_irve': '2022-06-06', 'file': 'consolidation-etalab-schema-irve-v-2.0.2-20220606-propre2.csv',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#      'chemin': 'D:\\\\philippe\\\\python ESstandard\\\\Environmental-Sensing\\\\python\\\\Validation\\\\irve\\\\'}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mirve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chemin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'len_irve'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mirve\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nombre de lignes : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'len_irve'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[1;31m# open URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    714\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Opensource\\anaconda3\\envs\\observ_v10_20230430\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from observation import Ilist, Analysis\n",
    "import pandas as pd\n",
    "#date = '2023-03-03'\n",
    "#date = '2023-04-17'\n",
    "date = '2023-05-02'\n",
    "log = {'date_irve': date, \n",
    "       'file': 'consolidation-etalab-schema-irve-statique-v-2.2.0-'+date[:4]+date[5:7]+date[8:]+'.csv',\n",
    "      'chemin': 'https://raw.githubusercontent.com/loco-philippe/Environmental-Sensing/main/python/Validation/irve/Analyse/'}\n",
    "#log = {'date_irve': '2022-06-06', 'file': 'consolidation-etalab-schema-irve-v-2.0.2-20220606-propre2.csv',\n",
    "#      'chemin': 'D:\\\\philippe\\\\python ESstandard\\\\Environmental-Sensing\\\\python\\\\Validation\\\\irve\\\\'}\n",
    "irve = pd.read_csv(log['chemin'] + log['file'], sep=',', low_memory=False)\n",
    "log['len_irve'] = len(irve)\n",
    "print('nombre de lignes : ', log['len_irve']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schéma de données\n",
    "Le schéma de données restreint à la propriété 'relationship' et construit à partir du modèle de données est le suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complément à inclure dans le schéma de données\n",
    "fields = [\n",
    " \n",
    " # relation unicité des pdl\n",
    " { \"name\": \"index\",\n",
    "   \"relationship\" : { \"parent\" : \"id_pdc_itinerance\", \"link\" : \"coupled\" }},   \n",
    " # relations inter entités\n",
    " { \"name\": \"contact_operateur\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"nom_enseigne\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"coordonneesXY\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"id_station_itinerance\",\n",
    "   \"relationship\" : { \"parent\" : \"id_pdc_itinerance\",     \"link\" : \"derived\" }},\n",
    " # relations intra entité - station\n",
    " { \"name\": \"nom_station\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"implantation_station\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " #{ \"name\": \"date_maj\",\n",
    " #  \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"nbre_pdc\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"condition_acces\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"horaires\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " { \"name\": \"station_deux_roues\",\n",
    "   \"relationship\" : { \"parent\" : \"id_station_itinerance\", \"link\" : \"derived\" }},\n",
    " # relations intra entité - localisation\n",
    " { \"name\": \"adresse_station\",\n",
    "   \"relationship\" : { \"parent\" : \"coordonneesXY\",         \"link\" : \"derived\" }} ]\n",
    "\n",
    "# liste des champs liés à un controle (relations) et obligatoires (mandatory)\n",
    "relations = ['index', 'contact_operateur', 'nom_enseigne', 'coordonneesXY', 'adresse_station', 'id_station_itinerance', \n",
    "             'nom_station', 'implantation_station', 'nbre_pdc', 'condition_acces', 'horaires', 'station_deux_roues', \n",
    "             'id_pdc_itinerance', 'date_maj', 'last_modified']\n",
    "mandatory =  ['contact_operateur', 'nom_enseigne', 'coordonneesXY', 'adresse_station', 'id_station_itinerance', 'nom_station',\n",
    "           'implantation_station', 'nbre_pdc', 'condition_acces', 'horaires', 'station_deux_roues', 'id_pdc_itinerance', \n",
    "           'puissance_nominale', 'prise_type_ef', 'prise_type_2', 'prise_type_combo_ccs', 'prise_type_chademo', \n",
    "           'prise_type_autre', 'paiement_acte', 'paiement_autre', 'reservation',  'accessibilite_pmr', 'restriction_gabarit', \n",
    "           'date_maj', 'last_modified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## 3 - Séparation des pdc itinerance et hors itinerance\n",
    "- un peu moins de 1 % des points de charge sont hors itinerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des données\n",
    "data = irve\n",
    "data[['id_station_itinerance','id_pdc_itinerance']] = data[['id_station_itinerance','id_pdc_itinerance']].astype('string')\n",
    "#data[['last_modified','date_maj']] = data[['last_modified','date_maj']].astype('datetime64')\n",
    "data['non_concerne'] = data['id_station_itinerance'].str.contains('oncern') | data['id_pdc_itinerance'].str.contains('oncern')\n",
    "\n",
    "non_concerne = data[data['non_concerne']].reset_index()['index']\n",
    "itinerance = data[~data['non_concerne']].reset_index()\n",
    "itinerance_init = itinerance.loc[:, relations]\n",
    "log['pdc_hors_itinerance'] = len(non_concerne)\n",
    "log['pdc_en_itinerance'] = len(itinerance)\n",
    "print('nombre de pdc hors itinerance : ', log['pdc_hors_itinerance'])\n",
    "print('nombre de pdc en itinerance   : ', log['pdc_en_itinerance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arborescence des champs et nombre de valeurs différentes\n",
    "il = Ilist.obj(itinerance_init)\n",
    "print(il.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## 4 - Bilan initial intégrité\n",
    "- 50 % des lignes présentent un défaut d'intégrité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation données bonnes (itinerance_ok_1) et données résiduelles (itinerance_1)\n",
    "res = analyse_integrite(itinerance_init, fields)\n",
    "itinerance_ok_1 = itinerance_init.loc[itinerance_init.ok, relations].reset_index(drop=True)\n",
    "itinerance_1 = itinerance_init.loc[~itinerance_init.ok, relations].reset_index(drop=True)\n",
    "itinerance_init = itinerance_init.loc[:, relations]\n",
    "log['init_ok'] = len(itinerance_ok_1)\n",
    "log['init_ko'] = len(itinerance_1)\n",
    "print(\"\\nnombre d'enregistrements sans erreurs : \", log['init_ok'])\n",
    "print(\"nombre d'enregistrements avec au moins une erreur : \", log['init_ko'])\n",
    "print(\"taux d'erreur : \", round(log['init_ko'] / log['pdc_en_itinerance'] * 100), ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## 5 - Séparation doublons pdc - date de maj\n",
    "- plus de la moitié des pdc en erreur sont liées aux doublons de pdc\n",
    "- la suppression des doublons permet de diviser par 10 le nombre de lignes erronnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation doublons pdc (doublons_pdc) et données résiduelles (itinerance_2)\n",
    "itinerance_1['doublons_pdc'] = itinerance_1.sort_values(by=['date_maj', 'last_modified']).duplicated('id_pdc_itinerance', keep='last')\n",
    "\n",
    "doublons_pdc = itinerance_1[itinerance_1['doublons_pdc']].loc[:, relations].reset_index(drop=True)['index']\n",
    "itinerance_2 = itinerance_1[~itinerance_1['doublons_pdc']].loc[:, relations].reset_index(drop=True)\n",
    "itinerance_1 = itinerance_1.loc[:, relations]\n",
    "log['doublons_pdc'] = len(doublons_pdc)\n",
    "log['sans_doublons_pdc'] = len(itinerance_2)\n",
    "print('nombre de doublons pdc : ', log['doublons_pdc'], ' soit ', round(log['doublons_pdc']/log['init_ko'] * 100), ' %')\n",
    "print('nombre de pdc sans doublon   : ', log['sans_doublons_pdc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation données bonnes (itinerance_ok_3) et données résiduelles (itinerance_3)\n",
    "res = analyse_integrite(itinerance_2, fields)\n",
    "itinerance_ok_3 = itinerance_2.loc[itinerance_2.ok, relations].reset_index(drop=True)\n",
    "itinerance_3 = itinerance_2.loc[~itinerance_2.ok, relations].reset_index(drop=True)\n",
    "itinerance_2 = itinerance_2.loc[:, relations]\n",
    "log['etape3_ok'] = len(itinerance_ok_3)\n",
    "log['etape3_ko'] = len(itinerance_3)\n",
    "print(\"\\nnombre d'enregistrements sans erreurs : \", log['etape3_ok'])\n",
    "print(\"nombre d'enregistrements avec au moins une erreur : \", log['etape3_ko'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## 6 - Séparation doublons station - date de maj\n",
    "- 15% des erreurs résiduelles sont liées au mélange d'anciens et de nouveaux pdc\n",
    "- la suppression des anciens pdc permet de réduire de 22% le nombre de lignes erronnées ( 1 616 )\n",
    "- les dernières erreurs correspondent à des stations associées à 32 opérateurs et sont liées à des causes multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation doublons stations (doublons_stat_maj) et données résiduelles (itinerance_4)\n",
    "itinerance_3['stat_maj'] = itinerance_3.id_station_itinerance + itinerance_3.date_maj\n",
    "stat_maj_unique = itinerance_3.sort_values(by='stat_maj').drop_duplicates('id_station_itinerance', keep='last')\n",
    "itinerance_3['last_stat_maj'] = itinerance_3['stat_maj'].isin(stat_maj_unique['stat_maj'])\n",
    "\n",
    "doublons_stat_maj = itinerance_3[~itinerance_3['last_stat_maj']].loc[:, relations].reset_index(drop=True)['index']\n",
    "itinerance_4 = itinerance_3[itinerance_3['last_stat_maj']].loc[:, relations].reset_index(drop=True)\n",
    "itinerance_3 = itinerance_3.loc[:, relations]\n",
    "log['doublons_station'] = len(doublons_stat_maj)\n",
    "log['sans_doublons_station'] = len(itinerance_4)\n",
    "print('nombre de doublons stations : ', log['doublons_station'], ' soit ', \n",
    "      round(log['doublons_station']/log['etape3_ko'] * 100), ' %')\n",
    "print('nombre de pdc sans doublon   : ', log['sans_doublons_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation données bonnes (itinerance_ok_5) et données résiduelles (itinerance_5 / itinerance_5_full)\n",
    "res = analyse_integrite(itinerance_4, fields)\n",
    "itinerance_ok_5 = itinerance_4.loc[itinerance_4.ok, relations].reset_index(drop=True)\n",
    "itinerance_5_full = itinerance_4.loc[~itinerance_4.ok].reset_index(drop=True)\n",
    "itinerance_5 = itinerance_5_full.loc[:, relations]\n",
    "#itinerance_4 = itinerance_4.loc[:, relations]\n",
    "log['etape5_ok'] = len(itinerance_ok_5)\n",
    "log['etape5_ko'] = len(itinerance_5)\n",
    "print(\"\\nnombre d'enregistrements sans erreurs : \", log['etape5_ok'])\n",
    "print(\"nombre d'enregistrements avec au moins une erreur : \", log['etape5_ko'], ' soit ', \n",
    "      round(log['etape5_ko']/log['etape3_ko'] * 100), ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure des données résiduelles et nombre de valeurs\n",
    "il = Ilist.obj(itinerance_5)\n",
    "print(il.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb maxi d'erreurs\n",
    "itinerance_4['somme'] = 0\n",
    "for name in res.keys():\n",
    "    itinerance_4['somme'] += 1 - itinerance_4[name]\n",
    "erreurs = max(itinerance_4['somme'])\n",
    "maxi = itinerance_4[itinerance_4.somme >= erreurs]\n",
    "print(\"nombre d'enregistrements avec \", erreurs, \" erreurs : \", len(maxi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## 7 - Synthèse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fichiers\n",
    "Génération des fichiers intégrant les défauts d'intégrité :\n",
    "- fichier csv des lignes résiduelles à traiter (IRVE_itinerance_residuel)\n",
    "- fichier csv des données itinerance avec indicateur des données à corriger ou à ignorer (IRVE_itinerance_complet)\n",
    "- fichier csv des données itinerance valides (IRVE_itinerance_valide)\n",
    "- fichier csv des doublons (IRVE_itinerance_doublons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidation des données\n",
    "itinerance['doublons_stat_maj'] = itinerance['index'].isin(doublons_stat_maj)\n",
    "itinerance['doublons_pdc'] = itinerance['index'].isin(doublons_pdc)\n",
    "itinerance['lignes_a_corriger'] = itinerance['index'].isin(itinerance_5['index'])\n",
    "itinerance['doublons_a_supprimer'] = itinerance['doublons_stat_maj'] | itinerance['doublons_pdc']\n",
    "itinerance['lignes_ko'] = itinerance['doublons_a_supprimer'] | itinerance['lignes_a_corriger']\n",
    "print('total des lignes à corriger : ', itinerance['lignes_a_corriger'].sum())\n",
    "itinerance_doublons = itinerance[itinerance['doublons_a_supprimer']].reset_index(drop=True)\n",
    "print('total des doublons à supprimer : ', len(itinerance_doublons))\n",
    "itinerance_ok = itinerance[~itinerance['lignes_ko']].reset_index(drop=True)\n",
    "print('nombre de pdc avec controles ok : ', len(itinerance_ok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#génération des fichiers\n",
    "extension = log['date_irve'] +'.csv'\n",
    "itinerance_5_full.to_csv('IRVE_itinerance_residuel' + extension)\n",
    "itinerance.to_csv('IRVE_itinerance_complet' + extension)\n",
    "itinerance_ok.to_csv('IRVE_itinerance_valide' + extension)\n",
    "itinerance_doublons.to_csv('IRVE_itinerance_doublons' + extension)\n",
    "log['IRVE_itinerance_residuel' + extension] = len(itinerance_5_full)\n",
    "log['IRVE_itinerance_complet' + extension] = len(itinerance)\n",
    "log['IRVE_itinerance_valide' + extension] = len(itinerance_ok)\n",
    "log['IRVE_itinerance_valide_stat' + extension] = len(itinerance_ok.drop_duplicates('id_station_itinerance', keep='last'))\n",
    "log['IRVE_itinerance_doublons' + extension] = len(itinerance_doublons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vérification de l'intégrité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérification de l'absence d'erreurs\n",
    "res = analyse_integrite(itinerance_ok.loc[:, relations], fields, pr=False)\n",
    "log['bilan_erreurs'] = sum([len(controle) for controle in res.values()])\n",
    "log['date'] = datetime.now().isoformat()\n",
    "print('bilan intégrité :')\n",
    "print('    erreurs : ', log['bilan_erreurs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure des données bonnes\n",
    "il = Ilist.obj(itinerance_ok.loc[:, mandatory])\n",
    "print(il.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# génération des indicateurs\n",
    "regles = ['Pdc non unique', 'Station multi-operateurs', 'Station multi-enseignes', 'Station multi-localisations', \n",
    "          'Pdc multi-stations', 'station avec plusieurs noms', 'station multi-implantations', \n",
    "          'nombre de pdc par station incoherent', 'station multi-acces', 'station multi-horaires', \n",
    "          'acces deux-roues incoherent', 'localisation multi-adresses']\n",
    "principal = [16, 17, 18, 19, 20]\n",
    "secondaire = [21, 22, 23, 24, 25, 26, 27]\n",
    "irve = itinerance_5_full # residuel\n",
    "total = len(irve)\n",
    "indic = {}\n",
    "\n",
    "irve['principal'] = True\n",
    "for ind in principal:\n",
    "    irve['principal'] &= irve.iloc[:,ind]\n",
    "    indic[regles[ind-16]] = int(total - irve.iloc[:,ind].sum())\n",
    "irve['secondaire'] = True\n",
    "for ind in secondaire:\n",
    "    irve['secondaire'] &= irve.iloc[:,ind]\n",
    "    indic[regles[ind-16]] = int(total - irve.iloc[:,ind].sum())\n",
    "irve['secondaire'] |= (~irve['principal'] & ~irve['secondaire'])\n",
    "irve['verif'] = irve['principal'] & irve['secondaire']\n",
    "indic['principal pdc'] = int(total - irve['principal'].sum())\n",
    "indic['secondaire pdc'] = int(total - irve['secondaire'].sum())\n",
    "\n",
    "irve_p = irve[~irve['principal']].drop_duplicates('id_station_itinerance').reset_index(drop=True)\n",
    "irve_s = irve[~irve['secondaire']].drop_duplicates('id_station_itinerance').reset_index(drop=True)\n",
    "indic['principal stat'] = len(irve_p)\n",
    "indic['secondaire stat'] = len(irve_s)\n",
    "\n",
    "log |= indic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stockage des indicateurs\n",
    "with open('logfile.txt', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(log) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## 8 - Exemples d'erreurs résiduelles \n",
    "\n",
    "### Erreurs multiples \n",
    "- exemple avec le nombre maximal d'erreurs (4) (2 stations soit 12 pdc avec : adresse, nom, nbre_pdc et deux-roues erronés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxi.loc[:, relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohérence implantation_station - id_station\n",
    "- 23 pdc sont liés à une erreur de choix d'implantation (3 stations, 1 opérateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itinerance_4.loc[~itinerance_4['implantation_station - id_station_itinerance'], relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohérence nom_station - id_station\n",
    "- 40 pdc sont associés à une station avec un nom non cohérent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itinerance_4.loc[~itinerance_4['nom_station - id_station_itinerance'], relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohérence adresse - coordonnées\n",
    "- 414 pdc ont une adresse non cohérente avec les coordonnées géographiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itinerance_4.loc[~itinerance_4['adresse_station - coordonneesXY'], relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : une station avec plusieurs adresses -> erreur de saisie ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itinerance_5.loc[itinerance_5.coordonneesXY\t == '[0.193942, 49.544211]', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : une station avec plusieurs adresses -> erreur de saisie ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itinerance_5.loc[itinerance_5.coordonneesXY\t == '[2.87930851314442, 48.94679007929618]', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohérence station - coordonnées\n",
    "- 216 pdc sont associés à des stations avec plusieurs coordonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itinerance_4.loc[~itinerance_4['coordonneesXY - id_station_itinerance'], relations][200:215]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : une station avec plusieurs coordonnées -> incompréhension distinction station / pdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinerance_5.loc[itinerance_5.id_station_itinerance == 'FR073PCAMAIEUFR', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : une station avec plusieurs coordonnées -> erreur de saisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinerance_5.loc[itinerance_5.id_station_itinerance == 'FRV75PPX0704', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : deux stations avec une localisation identique mais deux adresses différentes (pb UTF8) + id identique entre station et pdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itinerance_5.loc[itinerance_5.coordonneesXY\t == '[0.193942, 49.544211]', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incohérence 'nbre_pdc'\n",
    "- 25% des pdc ont un champ 'nbre_pdc' mal documenté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : station avec un pdc 'de regroupement' qui évite de documenter plusieurs lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinerance_init.loc[itinerance_init.id_station_itinerance == 'FRLUMEACACIAS11', \n",
    "               ['id_pdc_itinerance', 'id_station_itinerance', 'coordonneesXY', 'nbre_pdc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : station avec plusieurs pdc mais l'id_station est identique à l'id_pdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinerance_init.loc[itinerance_init.coordonneesXY\t == '[2.451322, 45.66523]', \n",
    "                   ['id_pdc_itinerance', 'id_station_itinerance', 'coordonneesXY', 'nbre_pdc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exemple : station avec plusieurs pdc mais le champs a toujours une valeur de 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itinerance_init.loc[itinerance_init.coordonneesXY\t == '[-1.7548354193520386, 48.125067030488154]', \n",
    "                   ['id_pdc_itinerance', 'id_station_itinerance', 'coordonneesXY', 'nbre_pdc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cohérence station - enseigne\n",
    "- exemple de station avec plusieurs noms d'enseigne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itinerance_init.loc[itinerance_init.id_station_itinerance == 'FRS27PBARREOUCHEMOMORT', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cohérence station - horaires\n",
    "- exemple de station avec plusieurs types d'horaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itinerance_init.loc[itinerance_init.id_station_itinerance == 'FRS23D2302001', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cohérence coordonnées - adresse\n",
    "- exemple de plusieurs stations avec des coordonnées identiques mais des adresses différentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itinerance_5.loc[itinerance_5.coordonneesXY == '[2.460441, 50.78763]', relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opérateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs = list(itinerance_5.drop_duplicates('contact_operateur')['contact_operateur'])\n",
    "for operateur in operateurs:\n",
    "    print(operateur, len(itinerance_5.loc[itinerance_5.contact_operateur == operateur]))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
