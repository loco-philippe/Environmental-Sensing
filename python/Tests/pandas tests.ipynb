{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objet : Test pandas\n",
    "\n",
    "## Objectif\n",
    "\n",
    "- list vers pandas series\n",
    "\n",
    "## Résultats\n",
    "- à préciser\n",
    "\n",
    "## Usages possibles \n",
    "- rempacement _keys et _keys par Series\n",
    "\n",
    "## Autres points\n",
    "- à tester\n",
    "\n",
    "données utilisées : https://files.data.gouv.fr/lcsqa/concentrations-de-polluants-atmospheriques-reglementes/temps-reel/2022/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           [1.0, 2.0]\n",
      "1                                           [1.0, 3.0]\n",
      "2                                           [2.0, 4.0]\n",
      "3    [[[1.0, 2.0], [1.0, 3.0], [2.0, 4.0], [1.0, 2....\n",
      "4    [[[1.0, 2.0], [1.0, 30.0], [30.0, 30.0], [30.0...\n",
      "dtype: object\n",
      "0         {'type': 'Point', 'coordinates': (1.0, 2.0)}\n",
      "1         {'type': 'Point', 'coordinates': (1.0, 3.0)}\n",
      "2         {'type': 'Point', 'coordinates': (2.0, 4.0)}\n",
      "3    {'type': 'Polygon', 'coordinates': (((1.0, 2.0...\n",
      "4    {'type': 'Polygon', 'coordinates': (((1.0, 2.0...\n",
      "dtype: object\n",
      "0         {\"type\": \"Point\", \"coordinates\": [1.0, 2.0]}\n",
      "1         {\"type\": \"Point\", \"coordinates\": [1.0, 3.0]}\n",
      "2         {\"type\": \"Point\", \"coordinates\": [2.0, 4.0]}\n",
      "3    {\"type\": \"Polygon\", \"coordinates\": [[[1.0, 2.0...\n",
      "4    {\"type\": \"Polygon\", \"coordinates\": [[[1.0, 2.0...\n",
      "dtype: object\n",
      "0         {'type': 'Point', 'coordinates': [1.0, 2.0]}\n",
      "1         {'type': 'Point', 'coordinates': [1.0, 3.0]}\n",
      "2         {'type': 'Point', 'coordinates': [2.0, 4.0]}\n",
      "3    {'type': 'Polygon', 'coordinates': [[[1.0, 2.0...\n",
      "4    {'type': 'Polygon', 'coordinates': [[[1.0, 2.0...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon\n",
    "from json_ntv import ShapelyConnec\n",
    "\n",
    "data =pd.Series([Point(1,2), Point(1,3), Point(2,4), Polygon([[1.0, 2.0], [1.0, 3.0], [2.0, 4.0]]),\n",
    "Polygon([[1.0, 2.0], [1.0, 30.0], [30.0, 30.0], [30,2]], [[[5.0, 16.0], [5.0, 27.0], [20.0, 27.0]]])])\n",
    "\n",
    "coor = data.apply(ShapelyConnec.to_coord)\n",
    "print(coor)\n",
    "\n",
    "coor2 = data.apply(shapely.geometry.mapping)\n",
    "print(coor2)\n",
    "\n",
    "coor3 = coor2.apply(json.dumps)\n",
    "print(coor3)\n",
    "\n",
    "coor4 = coor3.apply(json.loads)\n",
    "print(coor4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_04ac4_row2_col0, #T_04ac4_row2_col1 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_04ac4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_04ac4_level0_col0\" class=\"col_heading level0 col0\" >A</th>\n",
       "      <th id=\"T_04ac4_level0_col1\" class=\"col_heading level0 col1\" >B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04ac4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_04ac4_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_04ac4_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04ac4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_04ac4_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_04ac4_row1_col1\" class=\"data row1 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04ac4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_04ac4_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_04ac4_row2_col1\" class=\"data row2 col1\" >6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2254813bcd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "styler = df.style.highlight_max()\n",
    "\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<style type=\"text/css\">\\n#T_04ac4_row2_col0, #T_04ac4_row2_col1 {\\n  background-color: yellow;\\n}\\n</style>\\n<table id=\"T_04ac4\">\\n  <thead>\\n    <tr>\\n      <th class=\"blank level0\" >&nbsp;</th>\\n      <th id=\"T_04ac4_level0_col0\" class=\"col_heading level0 col0\" >A</th>\\n      <th id=\"T_04ac4_level0_col1\" class=\"col_heading level0 col1\" >B</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th id=\"T_04ac4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\\n      <td id=\"T_04ac4_row0_col0\" class=\"data row0 col0\" >1</td>\\n      <td id=\"T_04ac4_row0_col1\" class=\"data row0 col1\" >4</td>\\n    </tr>\\n    <tr>\\n      <th id=\"T_04ac4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\\n      <td id=\"T_04ac4_row1_col0\" class=\"data row1 col0\" >2</td>\\n      <td id=\"T_04ac4_row1_col1\" class=\"data row1 col1\" >5</td>\\n    </tr>\\n    <tr>\\n      <th id=\"T_04ac4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\\n      <td id=\"T_04ac4_row2_col0\" class=\"data row2 col0\" >3</td>\\n      <td id=\"T_04ac4_row2_col1\" class=\"data row2 col1\" >6</td>\\n    </tr>\\n  </tbody>\\n</table>\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styler.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Styler' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40204\\4177205743.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstyler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Styler' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "styler.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014781665802001954 0.05381264686584473 3.640499493538585 True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "coef = 40\n",
    "period = 20\n",
    "repeat = 50\n",
    "leng = coef * period * repeat\n",
    "lseq = coef * period\n",
    "tn = 0\n",
    "tp = 0\n",
    "for i in range(50):\n",
    "    t0 =time()\n",
    "    seq = np.stack(tuple([np.arange(period)] * coef), axis=1).reshape(lseq)\n",
    "    keys1 = list(np.stack(tuple([seq] * repeat)).reshape(leng))\n",
    "    tn += time()-t0\n",
    "\n",
    "    t0 =time()\n",
    "    keys2 = [(i % lseq) // coef for i in range(leng)]\n",
    "    tp += time()-t0\n",
    "print(tn/10, tp/10, tp/tn, keys1 == keys2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Initialisation\n",
    "- lecture des fichiers de 01/2022 issus de l'api (un fichier par jour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from time import time\n",
    "import csv\n",
    "import os\n",
    "#os.chdir('C:/Users/a179227/OneDrive - Alliance/perso Wx/ES standard/python ESstandard/ES')\n",
    "from util import util\n",
    "from observation import Ilist, Iindex\n",
    "from copy import copy\n",
    "\n",
    "chemin='C:/Users/a179227/OneDrive - Alliance/perso Wx/ES standard/Environnemental-Sensing/python/validation/air/data_lcsqa/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2021-01-01\n",
      "1    2022-01-02\n",
      "dtype: object\n",
      "[\"2021-01-01\",\"2022-01-02\"]\n",
      "True\n",
      "0    2021-01-01\n",
      "1    2022-01-02\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "sr = pd.Series([date(2021,1,1), date(2022, 1, 2)])\n",
    "print(sr)\n",
    "sr2 = sr.astype(str) # conversion date -> str\n",
    "js = sr2.to_json(orient='records', date_format='iso', default_handler=str)\n",
    "print(js)\n",
    "\n",
    "sr3 = pd.read_json(js, typ='series')\n",
    "sr4 = pd.to_datetime(sr3).dt.date # conversion str -> date\n",
    "print(sr4.equals(sr))\n",
    "print(sr4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2 197455 ['Date de début', 'Date de fin', 'Organisme', 'code zas', 'Zas', 'code site', 'nom site', \"type d'implantation\", 'Polluant', \"type d'influence\", 'discriminant', 'Réglementaire', \"type d'évaluation\", 'procédure de mesure', 'type de valeur', 'valeur', 'unité de mesure', 'taux de saisie', 'couverture temporelle', 'couverture de données', 'code qualité', 'validité'] 1.7311534881591797\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "t0 = time()\n",
    "annee = 2022\n",
    "mois = 1\n",
    "jour = 1\n",
    "for i in range(4):\n",
    "    file = chemin + 'FR_E2_' + str(annee) + '-' + format(mois, '02d') +'-' + format(jour+i, '02d') +'.csv'\n",
    "    data.append(pd.read_csv(file, sep=';'))\n",
    "data2 = pd.concat(data, ignore_index=True, join='inner').astype('category')\n",
    "data2.pop('valeur brute')\n",
    "print('data2', len(data2), list(data2), time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idxs (len, lenlidx, sumcodec) :  197455 22 4462 1.7334957122802734\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "idxs2 = Ilist.obj(data2)\n",
    "print('idxs (len, lenlidx, sumcodec) : ', len(idxs2), len(idxs2.idxlen), sum(idxs2.idxlen), time()-t0)\n",
    "#idxs2.delindex('valeur brute')\n",
    "idxs2.setvar('valeur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list to val old:  0.658961296081543\n",
      "list to codec :  0.008095264434814453\n",
      "list to cat simple :  0.5761041641235352\n",
      "list to cat :  1.3805665969848633\n",
      "list to cat :  1.4476771354675293\n",
      "list to val (def):  1.520902156829834\n",
      "list to val (all map):  1.7561311721801758\n",
      "list to val (all tuple):  2.2119081020355225\n",
      "cat to val (def):  0.17286372184753418\n",
      "cat to val (all):  0.20073533058166504\n",
      "simple to val (all series simple):  0.5166947841644287\n",
      "cat to val (all series):  0.18467140197753906\n"
     ]
    }
   ],
   "source": [
    "#calcul de values à partir de keys et codec\n",
    "t0=time()\n",
    "for idx in idxs2.lindex:\n",
    "    val = idx.values\n",
    "print('list to val old: ', time()-t0)\n",
    "#génération d'une liste de Series à partir d'une liste de codec\n",
    "t0=time()\n",
    "pdcodec=[pd.Series(idx.codec) for idx in idxs2.lindex]\n",
    "print('list to codec : ', time()-t0)#génération d'une liste de Series à partir d'une liste de keys\n",
    "#génération d'une liste de Series simple à partir d'une liste de keys\n",
    "t0=time()\n",
    "pdkeyss=[pd.Series(idx.keys, dtype='int64') for idx in idxs2.lindex]\n",
    "print('list to cat simple : ', time()-t0)\n",
    "#génération d'une liste de Series à partir d'une liste de keys\n",
    "t0=time()\n",
    "pdkeys=[pd.Series(idx.keys, dtype='category') for idx in idxs2.lindex]\n",
    "print('list to cat : ', time()-t0)\n",
    "#génération d'une liste de Series à partir d'une liste de keys\n",
    "pdkeys=[]\n",
    "t0=time()\n",
    "for idx in idxs2.lindex:\n",
    "    pdkeys.append(pd.Series(idx.keys, dtype='category'))\n",
    "print('list to cat : ', time()-t0)#calcul de values à partir de keys et codec avec une Series categorical (default)\n",
    "t0=time()\n",
    "for idx in idxs2.lindex:\n",
    "    val = list(pd.Series(idx.keys, dtype='category').cat.rename_categories(idx.codec))\n",
    "print('list to val (def): ', time()-t0)\n",
    "#calcul de values à partir de keys et codec avec une Series map (all)\n",
    "t0=time()\n",
    "for idx in idxs2.lindex:\n",
    "    val = list(pd.Series(idx.keys).map(pd.Series(idx.codec)))\n",
    "print('list to val (all map): ', time()-t0)\n",
    "#calcul de values à partir de keys et codec avec une Series (quelconque)\n",
    "t0=time()\n",
    "for idx, keys in zip(idxs2.lindex,pdkeys):\n",
    "    val = list(pd.DataFrame(keys.cat.rename_categories(pd.Series(zip(idx.codec, range(len(idx.codec))))).tolist())[0])\n",
    "print('list to val (all tuple): ', time()-t0)\n",
    "#calcul de values à partir d'une Series de keys et codec (default)\n",
    "t0=time()\n",
    "for idx, keys in zip(idxs2.lindex,pdkeys):\n",
    "    val = list(keys.cat.rename_categories(idx.codec))\n",
    "print('cat to val (def): ', time()-t0)\n",
    "#calcul de values à partir d'une Series de keys et codec avec une Series (quelconque)\n",
    "t0=time()\n",
    "for idx, keys in zip(idxs2.lindex,pdkeys):\n",
    "    val = list(keys.map(pd.Series(idx.codec)))\n",
    "print('cat to val (all): ', time()-t0)\n",
    "#calcul de values à partir d'une Series de keys et une series codec (quelconque)\n",
    "t0=time()\n",
    "for cod, keys in zip(pdcodec,pdkeyss):\n",
    "    val = list(keys.map(cod))\n",
    "print('simple to val (all series simple): ', time()-t0)\n",
    "#calcul de values à partir d'une Series de keys et une series codec (quelconque)\n",
    "t0=time()\n",
    "for cod, keys in zip(pdcodec,pdkeys):\n",
    "    val = list(keys.map(cod))\n",
    "print('cat to val (all series): ', time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "#print(val[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([\"date\", {\"test\": 3}, \"date2\"], dtype='object') \n",
      " [0, 2, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ESValue\n",
    "from observation import DatationValue, NamedValue\n",
    "ser = pd.Series([DatationValue('date'), DatationValue('date2'), DatationValue('date'), NamedValue(3,'test')], dtype='category')\n",
    "print(ser.cat.categories, '\\n', list(ser.cat.codes))\n",
    "ser2 = pd.Series([0,11,0,22]).astype('category')\n",
    "serbis = ser2.cat.rename_categories([DatationValue('date'), DatationValue('date2'),  NamedValue(3,'test')])\n",
    "min(ser.astype('object') == serbis.astype('object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name     plants quantity  product price\n",
      "var       False    False    False  True\n",
      "0         fruit       kg    apple   1.0\n",
      "1         fruit    10 kg    apple  10.0\n",
      "2         fruit       kg   orange   2.0\n",
      "3         fruit    10 kg   orange  20.0\n",
      "4     vegetable       kg  peppers   1.5\n",
      "5     vegetable    10 kg  peppers  15.0\n",
      "6     vegetable       kg   banana   0.5\n",
      "7         fruit    10 kg   banana   5.0\n"
     ]
    }
   ],
   "source": [
    "#generation dataframe à partir de Ilist\n",
    "ilm = Ilist.obj([['plants', ['fruit', 'fruit', 'fruit', 'fruit', 'vegetable', 'vegetable', 'vegetable', 'fruit']],\n",
    "                  ['quantity', ['kg', '10 kg', 'kg', '10 kg', 'kg', '10 kg', 'kg', '10 kg']],\n",
    "                  ['product', ['apple', 'apple', 'orange', 'orange', 'peppers', 'peppers', 'banana', 'banana']],\n",
    "                  ['price', [1, 10, 2, 20, 1.5, 15, 0.5, 5], -1]])\n",
    "df = pd.concat([idx.to_pandas(index=False, series=False).astype('category') for idx in ilm.lindex], axis=1)\n",
    "col = pd.MultiIndex.from_arrays([ilm.lname, ilm.lisvar], names=['name', 'var'])\n",
    "df.columns = col\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([0.5, 1.0, 1.5, 2.0, 5.0, 7.0, 10.0, 15.0, 20.0], dtype='float64')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fonction append\n",
    "s2 = pd.Series(['fruit', 'kg', 'banana', 7], index=df.columns)\n",
    "df = pd.concat([df, s2.to_frame().T], ignore_index=True).astype('category') \n",
    "ds = df['price'].squeeze()\n",
    "ds.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (b, 1)\n",
      "1    (a, 2)\n",
      "2    (a, 4)\n",
      "3    (d, 3)\n",
      "dtype: category\n",
      "Categories (4, object): [('a', 2), ('a', 4), ('b', 1), ('d', 3)]\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    2\n",
      "dtype: int8\n",
      "0    2\n",
      "1    0\n",
      "2    1\n",
      "3    3\n",
      "dtype: int8\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "a= pd.Series(['b', 'a', 'a', 'd']).astype('category')\n",
    "b = pd.Series([1,2,4,3]).astype('category')\n",
    "coup = pd.Series(list(zip(*(list(a), list(b))))).astype('category')\n",
    "print(coup)\n",
    "\n",
    "print(a.cat.codes)\n",
    "print(coup.cat.codes)\n",
    "res = coup.cat.codes == a.cat.codes\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    b\n",
      "4    c\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "a = pd.Series([0,1,2,3,2]).astype('category')\n",
    "codec = ['a', 'b', 'c', 'b']\n",
    "print(a.cat.codes.map(pd.Series(codec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>plants</th>\n",
       "      <th>quantity</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fruit</td>\n",
       "      <td>kg</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fruit</td>\n",
       "      <td>10 kg</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fruit</td>\n",
       "      <td>kg</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fruit</td>\n",
       "      <td>10 kg</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vegetable</td>\n",
       "      <td>kg</td>\n",
       "      <td>peppers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vegetable</td>\n",
       "      <td>10 kg</td>\n",
       "      <td>peppers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vegetable</td>\n",
       "      <td>kg</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fruit</td>\n",
       "      <td>10 kg</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name     plants quantity  product\n",
       "var       False    False    False\n",
       "0         fruit       kg    apple\n",
       "1         fruit    10 kg    apple\n",
       "2         fruit       kg   orange\n",
       "3         fruit    10 kg   orange\n",
       "4     vegetable       kg  peppers\n",
       "5     vegetable    10 kg  peppers\n",
       "6     vegetable       kg   banana\n",
       "7         fruit    10 kg   banana"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtrage suivant var\n",
    "df.loc[:,(slice(None),False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(False, 'plants'), ['fruit', 'fruit', 'fruit', 'fruit', 'vegetable', 'vegetable', 'vegetable', 'fruit']], [(False, 'quantity'), ['kg', '10 kg', 'kg', '10 kg', 'kg', '10 kg', 'kg', '10 kg']], [(False, 'product'), ['apple', 'apple', 'orange', 'orange', 'peppers', 'peppers', 'banana', 'banana']], [(True, 'price'), [1.0, 10.0, 2.0, 20.0, 1.5, 15.0, 0.5, 5.0]]] \n",
      "\n",
      "[[(False, 'plants'), ['fruit', 'vegetable'], [0, 0, 0, 0, 1, 1, 1, 0]], [(False, 'quantity'), ['10 kg', 'kg'], [1, 0, 1, 0, 1, 0, 1, 0]], [(False, 'product'), ['apple', 'banana', 'orange', 'peppers'], [0, 0, 2, 2, 3, 3, 1, 1]], [(True, 'price'), [0.5, 1.0, 1.5, 2.0, 5.0, 10.0, 15.0, 20.0], [1, 5, 3, 7, 2, 6, 0, 4]]]\n"
     ]
    }
   ],
   "source": [
    "full = [[name, list(ds)] for name,ds in df.items()]\n",
    "print(full, '\\n')\n",
    "default = [[name, list(ds.cat.categories), list(ds.cat.codes)] for name,ds in df.astype('category').items()]\n",
    "print(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two  three   four  total  somme\n",
      "0  1.0  4.0   True   True   True      0\n",
      "1  2.0  3.0  False   True  False      1\n",
      "2  3.0  2.0   True  False  False      1\n",
      "3  4.0  1.0  False  False  False      2\n",
      "2 1\n",
      "2 1\n",
      "   one  three   four  total\n",
      "3  4.0  False  False  False\n"
     ]
    }
   ],
   "source": [
    "d = {\"one\": [1.0, 2.0, 3.0, 4.0], \"two\": [4.0, 3.0, 2.0, 1.0]}\n",
    "df = pd.DataFrame(d)\n",
    "df[\"three\"] = True\n",
    "df[\"four\"] = [True, True, False, False]\n",
    "df[\"total\"] = True\n",
    "df['somme'] = 0\n",
    "f =[1,3]\n",
    "df.loc[f, \"three\"] = False\n",
    "df['total'] = df['total'] & df['three']\n",
    "df['total'] = df['total'] & df['four']\n",
    "df['somme'] = df['somme'] - df['three'] +1\n",
    "df['somme'] = df['somme'] - df['four'] +1\n",
    "print(df)\n",
    "print(df.four.sum(), df.total.sum())\n",
    "maxi = max(df.somme) \n",
    "df_max = df[df.somme == maxi]\n",
    "print(maxi, len(df_max))\n",
    "print(df_max.loc[:,('one','three', 'four', 'total')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['plants', ['fruit', 'fruit', 'fruit', 'fruit', 'vegetable', 'vegetable', 'vegetable', 'fruit']], ['quantity', ['kg', '10 kg', 'kg', '10 kg', 'kg', '10 kg', 'kg', '10 kg']], ['product', ['apple', 'apple', 'orange', 'orange', 'peppers', 'peppers', 'banana', 'banana']], ['price', [1, 10, 2, 20, 1.5, 15, 0.5, 5], -1]] \n",
      "\n",
      "[['plants', ['fruit', 'vegetable'], [0, 0, 0, 0, 1, 1, 1, 0]], ['quantity', ['kg', '10 kg'], [0, 1, 0, 1, 0, 1, 0, 1]], ['product', ['orange', 'apple', 'peppers', 'banana'], [1, 1, 0, 0, 2, 2, 3, 3]], ['price', [1, 10, 2, 20, 1.5, 15, 0.5, 5], -1]]\n"
     ]
    }
   ],
   "source": [
    "print(ilm.to_obj(modecodec='full'), '\\n')\n",
    "print(ilm.to_obj(modecodec='default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullsize 87068691 1.397794246673584\n",
      "defaultsize 24003010 1.4524955749511719\n"
     ]
    }
   ],
   "source": [
    "#generation de json (full et default)\n",
    "import json\n",
    "t0=time()\n",
    "full = json.dumps([[name, list(ds)] for name,ds in data2.items()])\n",
    "print('fullsize', len(full), time()-t0)\n",
    "t0=time()\n",
    "default = json.dumps([[name, list(ds.cat.categories), list(ds.cat.codes)] for name,ds in data2.astype('category').items()])\n",
    "print('defaultsize', len(default), time()-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullsize 86202592 15.800340414047241\n",
      "minsize 1694137 0.6880073547363281\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "fullsize = len(idxs2.to_obj(encoded=True, modecodec='full'))\n",
    "print('fullsize', fullsize, time()-t0)\n",
    "t0=time()\n",
    "minsize = len(idxs2.to_obj(encoded=True, modecodec='nokeys'))\n",
    "print('minsize', minsize, time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## format non optimisé\n",
    "- le \"taux d'unicité\" reste à 12% (pas de modification des index)\n",
    "- le \"taux de codage\" est de 30% (remplacement des données dupliquées par un entier)\n",
    "- le gain de taille de fichier par rapport à un fichier \"quoté\" est de 61%\n",
    "- l'analyse de la structure montre que les données sont principalement du type \"linked\" (non ou peu structuré)\n",
    "- quelques colonnes sont de type \"derived\". Par exemple les index longitude(43) et latitude(44) sont bien dérivés de l'index coordonneesXY(13)\n",
    "- le taux de couplage (\"linkrate\") pour chacun des index est très proche de 0, ce qui signifie que les données devraient être de type \"derived\" (lien de dépendance par exemple comme entre les trimestres et les mois) ou \"coupled\" (lien biunivoque)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultsize 22942572 1.483217477798462\n",
      "indicator default :  {'init values': 6507754, 'mean size': 13.246, 'unique values': 1654, 'mean coding size': 3.523, 'unicity level': 0.0, 'object lightness': 0.266, 'gain': 0.734}\n",
      "[{'lencodec': 144, 'name': 'Date de début', 'num': 0, 'parent': 5, 'typecoupl': 'linked'},\n",
      " {'lencodec': 144, 'name': 'Date de fin', 'num': 1, 'parent': 0, 'typecoupl': 'coupled'},\n",
      " {'lencodec': 18, 'name': 'Organisme', 'num': 2, 'parent': 5, 'typecoupl': 'derived'},\n",
      " {'lencodec': 70, 'name': 'code zas', 'num': 3, 'parent': 5, 'typecoupl': 'derived'},\n",
      " {'lencodec': 70, 'name': 'Zas', 'num': 4, 'parent': 3, 'typecoupl': 'coupled'},\n",
      " {'lencodec': 533, 'name': 'code site', 'num': 5, 'parent': 5, 'typecoupl': 'crossed'},\n",
      " {'lencodec': 533, 'name': 'nom site', 'num': 6, 'parent': 5, 'typecoupl': 'linked'},\n",
      " {'lencodec': 5, 'name': \"type d'implantation\", 'num': 7, 'parent': 5, 'typecoupl': 'derived'},\n",
      " {'lencodec': 9, 'name': 'Polluant', 'num': 8, 'parent': 13, 'typecoupl': 'linked'},\n",
      " {'lencodec': 3, 'name': \"type d'influence\", 'num': 9, 'parent': 12, 'typecoupl': 'linked'},\n",
      " {'lencodec': 26, 'name': 'discriminant', 'num': 10, 'parent': 13, 'typecoupl': 'linked'},\n",
      " {'lencodec': 1, 'name': 'Réglementaire', 'num': 11, 'parent': 11, 'typecoupl': 'unique'},\n",
      " {'lencodec': 4, 'name': \"type d'évaluation\", 'num': 12, 'parent': 7, 'typecoupl': 'linked'},\n",
      " {'lencodec': 60, 'name': 'procédure de mesure', 'num': 13, 'parent': 3, 'typecoupl': 'linked'},\n",
      " {'lencodec': 2, 'name': 'type de valeur', 'num': 14, 'parent': 2, 'typecoupl': 'linked'},\n",
      " {'lencodec': 3, 'name': 'unité de mesure', 'num': 15, 'parent': 12, 'typecoupl': 'linked'},\n",
      " {'lencodec': 1, 'name': 'taux de saisie', 'num': 16, 'parent': 16, 'typecoupl': 'unique'},\n",
      " {'lencodec': 1, 'name': 'couverture temporelle', 'num': 17, 'parent': 17, 'typecoupl': 'unique'},\n",
      " {'lencodec': 1, 'name': 'couverture de données', 'num': 18, 'parent': 18, 'typecoupl': 'unique'},\n",
      " {'lencodec': 3, 'name': 'code qualité', 'num': 19, 'parent': 14, 'typecoupl': 'crossed'},\n",
      " {'lencodec': 2, 'name': 'validité', 'num': 20, 'parent': 19, 'typecoupl': 'derived'}]\n",
      "[{'linkrate': 1.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 1.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.05},\n",
      " {'linkrate': 0.75},\n",
      " {'linkrate': 0.14},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.73},\n",
      " {'linkrate': 0.11},\n",
      " {'linkrate': 0.06},\n",
      " {'linkrate': 0.62},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 0.0},\n",
      " {'linkrate': 1.0},\n",
      " {'linkrate': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "defaultsize = len(idxs2.to_obj(encoded=True, modecodec='default'))\n",
    "print('defaultsize', defaultsize, time()-t0)\n",
    "print('indicator default : ', idxs2.indicator(fullsize, defaultsize))\n",
    "pprint(idxs2.indexinfos(keys=['num', 'name', 'lencodec', 'parent', 'typecoupl']), width=120)\n",
    "pprint(idxs2.indexinfos(keys=['linkrate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Format optimisé\n",
    "- le \"taux d'unicité\" se dégrade légèrement (passage de 11,6% à 12,1%) par l'ajout d'index supplémentaires\n",
    "- le \"taux de codage\" par contre passe de 30% à 16% de par l'optimisation \n",
    "- le gain de taille de fichier par rapport à un fichier \"quoté\" est maintenant de 74%\n",
    "- l'utilisation d'un format binaire (codage CBOR pour Concise Binary Object Representation RFC 8949) permet d'améliorer encore le gain de taille de fichier (82%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizesize  13139380 2.0916759967803955\n",
      "indicator optimize :  {'init values': 6507754, 'mean size': 13.246, 'unique values': 1654, 'mean coding size': 2.016, 'unicity level': 0.0, 'object lightness': 0.152, 'gain': 0.848}\n",
      "cborsize 6852732 1.8763666152954102\n",
      "indicator cbor :  {'init values': 6507754, 'mean size': 13.246, 'unique values': 1654, 'mean coding size': 1.05, 'unicity level': 0.0, 'object lightness': 0.079, 'gain': 0.921}\n"
     ]
    }
   ],
   "source": [
    "#idxs.setcanonorder().sort()\n",
    "t0=time()\n",
    "optimizesize = len(idxs2.to_obj(modecodec='optimize', encoded=True))\n",
    "print('optimizesize ', optimizesize, time()-t0)\n",
    "print('indicator optimize : ', idxs2.indicator(fullsize, optimizesize))\n",
    "t0=time()\n",
    "js = idxs2.to_obj(encoded=True, modecodec='optimize', format='cbor')\n",
    "cborsize = len(js)\n",
    "print('cborsize', cborsize, time()-t0)\n",
    "print('indicator cbor : ', idxs2.indicator(fullsize, cborsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Intégrité\n",
    "- la transformation inverse des données binaires permet de vérifier qu'on retombe bien sur les mêmes données (pas de dégradation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fromcbor 295807 4.430227041244507\n",
      "controle égalité : True 2.1935391426086426\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "idxs3 = Ilist.from_obj(js)\n",
    "print('fromcbor', len(idxs3), time()-t0)\n",
    "t0=time()\n",
    "verif = idxs2 == idxs3\n",
    "print('controle égalité :', verif, time()-t0)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
